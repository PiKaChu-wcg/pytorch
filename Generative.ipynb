{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMBpePVbXmv9h/tUUNKYyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiKaChu-wcg/pytorch/blob/main/Generative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEbX15KuP7_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699edba5-9c25-4054-8bed-a00273be75de"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import torchvision.datasets as dsets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutil\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import os\r\n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\r\n",
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 08:35:17--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-18 08:35:17--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [           <=>      ]  33.20M  11.6MB/s    in 2.9s    \n",
            "\n",
            "2021-03-18 08:35:20 (11.6 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzh7-XyxQFQ0"
      },
      "source": [
        "image_size=28\r\n",
        "input_dim=100\r\n",
        "num_channels=1\r\n",
        "num_features=64\r\n",
        "batch_size=64\r\n",
        "use_cuda=torch.cuda.is_available()\r\n",
        "dtype=torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\r\n",
        "itype=torch.cuda.LongTensor if use_cuda else torch.LongTensor\r\n",
        "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\r\n",
        "                            train=True,   #提取训练集\r\n",
        "                            transform=transforms.ToTensor(),  #将图像转化为Tensor，在加载数据的时候，就可以对图像做预处理\r\n",
        "                            download=True)\r\n",
        "test_dataset = dsets.MNIST(root='./data', \r\n",
        "                           train=False, \r\n",
        "                           transform=transforms.ToTensor())\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)\r\n",
        "indices = range(len(test_dataset))\r\n",
        "indices_val = indices[:5000]\r\n",
        "indices_test = indices[5000:]\r\n",
        "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\r\n",
        "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\r\n",
        "validation_loader = torch.utils.data.DataLoader(dataset =test_dataset,\r\n",
        "                                                batch_size = batch_size,\r\n",
        "                                                sampler = sampler_val\r\n",
        "                                               )\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          sampler = sampler_test\r\n",
        "                                         )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpsXGfxtSuCF"
      },
      "source": [
        "class ModuleG(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ModuleG,self).__init__()\r\n",
        "        self.model=nn.Sequential()\r\n",
        "        self.model.add_module('deconv1',nn.ConvTranspose2d(input_dim,num_features*2,5,22,0,bias=False))\r\n",
        "        self.model.add_module('bonrm1',nn.BatchNorm2d(num_features*2))\r\n",
        "        self.model.add_module('relu1',nn.ReLU(True))\r\n",
        "        self.model.add_module('deconv2',nn.ConvTranspose2d(num_features*2,num_features,5,2,0,bias=False))\r\n",
        "        self.model.add_module('bonrm2',nn.BatchNorm2d(num_features))\r\n",
        "        self.model.add_module('relu2',nn.ReLU(True))\r\n",
        "        self.model.add_module('deconv3',nn.ConvTranspose2d(num_features, num_channels, 4, 2, 0,bias=False))\r\n",
        "        self.model.add_module('sigmoid',nn.Sigmoid())\r\n",
        "    def forward(self,input):\r\n",
        "        output=input\r\n",
        "        for name,module in self.model.named_children():\r\n",
        "            output=module(output)\r\n",
        "        return (output)\r\n",
        "def weight_init(m):\r\n",
        "    class_name=m.__class__.__name__\r\n",
        "    if  class_name.find('conv')!=-1:\r\n",
        "        m.weight.data.normal_(0,0.02)\r\n",
        "    if class_name.find('norm')!=-1:\r\n",
        "        m.weight.data.normal_(1.0,0.02)\r\n",
        "def make_show(img):\r\n",
        "    img=img.data.expand(batch_size,3,image_size,image_size)\r\n",
        "    return img\r\n",
        "\r\n",
        "def imshow(inp, title=None):\r\n",
        "    # 在屏幕上绘制图像\r\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\r\n",
        "    if inp.size()[0] > 1:\r\n",
        "        inp = inp.numpy().transpose((1, 2, 0))\r\n",
        "    else:\r\n",
        "        inp = inp[0].numpy()\r\n",
        "    mvalue = np.amin(inp)\r\n",
        "    maxvalue = np.amax(inp)\r\n",
        "    if maxvalue > mvalue:\r\n",
        "        inp = (inp - mvalue)/(maxvalue - mvalue)\r\n",
        "    plt.imshow(inp)\r\n",
        "    if title is not None:\r\n",
        "        plt.title(title)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn262NsJbnVM",
        "outputId": "9ea600a1-7d96-4ed8-e3e4-2b9c7876029a"
      },
      "source": [
        "net=ModuleG()\r\n",
        "net=net.cuda() if use_cuda else net\r\n",
        "criterion=nn.MSELoss()\r\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.9)\r\n",
        "samples=np.random.choice(10,batch_size)\r\n",
        "samples=torch.from_numpy(samples).type(dtype)\r\n",
        "step=0\r\n",
        "num_epochs=20\r\n",
        "record=[]\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    train_loss=[]\r\n",
        "    for batch_idx,(data,target) in enumerate(train_loader):\r\n",
        "        target,data=data.clone().detach().requires_grad_(True),target.clone().detach()\r\n",
        "        if use_cuda:\r\n",
        "            target, data = target.cuda(), data.cuda()\r\n",
        "        data = data.type(dtype)\r\n",
        "        data = data.resize(data.size()[0], 1, 1, 1)\r\n",
        "        data = data.expand(data.size()[0], input_dim, 1, 1)\r\n",
        "        net.train()\r\n",
        "        output=net(data)\r\n",
        "        loss=criterion(output,target)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        step+=1\r\n",
        "        if use_cuda:\r\n",
        "            loss = loss.cpu()\r\n",
        "        train_loss.append(loss.data.numpy())\r\n",
        "        \r\n",
        "        \r\n",
        "        if step % 100 == 0: #每间隔100个batch执行一次打印等操作    \r\n",
        "            net.eval() # 给网络模型做标记，标志说模型在校验集上运行\r\n",
        "            val_loss = [] #记录校验数据集准确率的容器\r\n",
        "            \r\n",
        "            '''开始在校验数据集上做循环，计算校验集上面的准确度'''\r\n",
        "            idx = 0\r\n",
        "            for (data, target) in validation_loader:\r\n",
        "                target, data = data.clone().detach().requires_grad_(True), target.clone().detach()\r\n",
        "                idx += 1\r\n",
        "                if use_cuda:\r\n",
        "                    target, data = target.cuda(), data.cuda()\r\n",
        "                data = data.type(dtype)\r\n",
        "                data = data.resize(data.size()[0], 1, 1, 1)\r\n",
        "                data = data.expand(data.size()[0], input_dim, 1, 1)\r\n",
        "                output = net(data) #完成一次前馈计算过程，得到目前训练得到的模型net在校验数据集上的表现\r\n",
        "                loss = criterion(output, target) #将output与标签target比较，计算误差\r\n",
        "                if use_cuda:\r\n",
        "                    loss = loss.cpu()\r\n",
        "                val_loss.append(loss.data.numpy())\r\n",
        "                #打印误差等数值，其中正确率为本训练周期Epoch开始后到目前撮的正确率的平均值\r\n",
        "            print('训练周期: {} [{}/{} ({:.0f}%)]\\t训练数据Loss: {:.6f}\\t校验数据Loss: {:.6f}'.format(\r\n",
        "                epoch, batch_idx * batch_size, len(train_loader.dataset),\r\n",
        "                100. * batch_idx / len(train_loader), np.mean(train_loss), np.mean(val_loss)))\r\n",
        "            record.append([np.mean(train_loss), np.mean(val_loss)])\r\n",
        "        \r\n",
        "    \r\n",
        "    # 产生一组图像保存到temp1文件夹下（需要事先建立好该文件夹），检测生成器当前的效果\r\n",
        "    # 改变输入数字的尺寸，适应于生成器网络\r\n",
        "    with torch.no_grad():\r\n",
        "        samples.resize_(batch_size,1,1,1)\r\n",
        "    samples = samples.data.expand(batch_size, input_dim, 1, 1)\r\n",
        "    samples = samples.cuda() if use_cuda else samples #加载到GPU\r\n",
        "    fake_u=net(samples) #用原始网络作为输入，得到伪造的图像数据\r\n",
        "    fake_u = fake_u.cpu() if use_cuda else fake_u\r\n",
        "    img = make_show(fake_u) #将张量转化成可绘制的图像\r\n",
        "    os.makedirs('temp1',exist_ok=True)\r\n",
        "    vutil.save_image(img,'temp1/fake%s.png'% (epoch)) #保存生成的图像      "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:474: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "训练周期: 0 [6336/60000 (11%)]\t训练数据Loss: 0.097351\t校验数据Loss: 0.067149\n",
            "训练周期: 0 [12736/60000 (21%)]\t训练数据Loss: 0.082248\t校验数据Loss: 0.063185\n",
            "训练周期: 0 [19136/60000 (32%)]\t训练数据Loss: 0.076504\t校验数据Loss: 0.061889\n",
            "训练周期: 0 [25536/60000 (43%)]\t训练数据Loss: 0.073442\t校验数据Loss: 0.061225\n",
            "训练周期: 0 [31936/60000 (53%)]\t训练数据Loss: 0.071488\t校验数据Loss: 0.060725\n",
            "训练周期: 0 [38336/60000 (64%)]\t训练数据Loss: 0.070171\t校验数据Loss: 0.060385\n",
            "训练周期: 0 [44736/60000 (75%)]\t训练数据Loss: 0.069146\t校验数据Loss: 0.060154\n",
            "训练周期: 0 [51136/60000 (85%)]\t训练数据Loss: 0.068343\t校验数据Loss: 0.060318\n",
            "训练周期: 0 [57536/60000 (96%)]\t训练数据Loss: 0.067699\t校验数据Loss: 0.060135\n",
            "训练周期: 1 [3904/60000 (7%)]\t训练数据Loss: 0.063023\t校验数据Loss: 0.059663\n",
            "训练周期: 1 [10304/60000 (17%)]\t训练数据Loss: 0.062274\t校验数据Loss: 0.059338\n",
            "训练周期: 1 [16704/60000 (28%)]\t训练数据Loss: 0.062284\t校验数据Loss: 0.059474\n",
            "训练周期: 1 [23104/60000 (38%)]\t训练数据Loss: 0.062095\t校验数据Loss: 0.059355\n",
            "训练周期: 1 [29504/60000 (49%)]\t训练数据Loss: 0.062150\t校验数据Loss: 0.059544\n",
            "训练周期: 1 [35904/60000 (60%)]\t训练数据Loss: 0.062080\t校验数据Loss: 0.058910\n",
            "训练周期: 1 [42304/60000 (70%)]\t训练数据Loss: 0.062074\t校验数据Loss: 0.059016\n",
            "训练周期: 1 [48704/60000 (81%)]\t训练数据Loss: 0.062056\t校验数据Loss: 0.059327\n",
            "训练周期: 1 [55104/60000 (92%)]\t训练数据Loss: 0.062062\t校验数据Loss: 0.058904\n",
            "训练周期: 2 [1472/60000 (2%)]\t训练数据Loss: 0.061515\t校验数据Loss: 0.058871\n",
            "训练周期: 2 [7872/60000 (13%)]\t训练数据Loss: 0.061490\t校验数据Loss: 0.058903\n",
            "训练周期: 2 [14272/60000 (24%)]\t训练数据Loss: 0.061393\t校验数据Loss: 0.058988\n",
            "训练周期: 2 [20672/60000 (34%)]\t训练数据Loss: 0.061503\t校验数据Loss: 0.058946\n",
            "训练周期: 2 [27072/60000 (45%)]\t训练数据Loss: 0.061571\t校验数据Loss: 0.058782\n",
            "训练周期: 2 [33472/60000 (56%)]\t训练数据Loss: 0.061533\t校验数据Loss: 0.058476\n",
            "训练周期: 2 [39872/60000 (66%)]\t训练数据Loss: 0.061458\t校验数据Loss: 0.058524\n",
            "训练周期: 2 [46272/60000 (77%)]\t训练数据Loss: 0.061487\t校验数据Loss: 0.058507\n",
            "训练周期: 2 [52672/60000 (88%)]\t训练数据Loss: 0.061413\t校验数据Loss: 0.058487\n",
            "训练周期: 2 [59072/60000 (98%)]\t训练数据Loss: 0.061407\t校验数据Loss: 0.058339\n",
            "训练周期: 3 [5440/60000 (9%)]\t训练数据Loss: 0.061336\t校验数据Loss: 0.058360\n",
            "训练周期: 3 [11840/60000 (20%)]\t训练数据Loss: 0.061297\t校验数据Loss: 0.058192\n",
            "训练周期: 3 [18240/60000 (30%)]\t训练数据Loss: 0.061271\t校验数据Loss: 0.058698\n",
            "训练周期: 3 [24640/60000 (41%)]\t训练数据Loss: 0.061118\t校验数据Loss: 0.058551\n",
            "训练周期: 3 [31040/60000 (52%)]\t训练数据Loss: 0.061105\t校验数据Loss: 0.058364\n",
            "训练周期: 3 [37440/60000 (62%)]\t训练数据Loss: 0.061125\t校验数据Loss: 0.058282\n",
            "训练周期: 3 [43840/60000 (73%)]\t训练数据Loss: 0.061090\t校验数据Loss: 0.058340\n",
            "训练周期: 3 [50240/60000 (84%)]\t训练数据Loss: 0.061048\t校验数据Loss: 0.058111\n",
            "训练周期: 3 [56640/60000 (94%)]\t训练数据Loss: 0.060994\t校验数据Loss: 0.058025\n",
            "训练周期: 4 [3008/60000 (5%)]\t训练数据Loss: 0.060497\t校验数据Loss: 0.057794\n",
            "训练周期: 4 [9408/60000 (16%)]\t训练数据Loss: 0.060833\t校验数据Loss: 0.057997\n",
            "训练周期: 4 [15808/60000 (26%)]\t训练数据Loss: 0.060764\t校验数据Loss: 0.058278\n",
            "训练周期: 4 [22208/60000 (37%)]\t训练数据Loss: 0.060763\t校验数据Loss: 0.058108\n",
            "训练周期: 4 [28608/60000 (48%)]\t训练数据Loss: 0.060764\t校验数据Loss: 0.057996\n",
            "训练周期: 4 [35008/60000 (58%)]\t训练数据Loss: 0.060808\t校验数据Loss: 0.057944\n",
            "训练周期: 4 [41408/60000 (69%)]\t训练数据Loss: 0.060723\t校验数据Loss: 0.058342\n",
            "训练周期: 4 [47808/60000 (80%)]\t训练数据Loss: 0.060684\t校验数据Loss: 0.058189\n",
            "训练周期: 4 [54208/60000 (90%)]\t训练数据Loss: 0.060654\t校验数据Loss: 0.057993\n",
            "训练周期: 5 [576/60000 (1%)]\t训练数据Loss: 0.060144\t校验数据Loss: 0.057768\n",
            "训练周期: 5 [6976/60000 (12%)]\t训练数据Loss: 0.060757\t校验数据Loss: 0.057663\n",
            "训练周期: 5 [13376/60000 (22%)]\t训练数据Loss: 0.060535\t校验数据Loss: 0.057732\n",
            "训练周期: 5 [19776/60000 (33%)]\t训练数据Loss: 0.060579\t校验数据Loss: 0.058181\n",
            "训练周期: 5 [26176/60000 (44%)]\t训练数据Loss: 0.060619\t校验数据Loss: 0.058044\n",
            "训练周期: 5 [32576/60000 (54%)]\t训练数据Loss: 0.060580\t校验数据Loss: 0.057960\n",
            "训练周期: 5 [38976/60000 (65%)]\t训练数据Loss: 0.060528\t校验数据Loss: 0.057863\n",
            "训练周期: 5 [45376/60000 (76%)]\t训练数据Loss: 0.060510\t校验数据Loss: 0.057644\n",
            "训练周期: 5 [51776/60000 (86%)]\t训练数据Loss: 0.060507\t校验数据Loss: 0.057697\n",
            "训练周期: 5 [58176/60000 (97%)]\t训练数据Loss: 0.060485\t校验数据Loss: 0.057509\n",
            "训练周期: 6 [4544/60000 (8%)]\t训练数据Loss: 0.060430\t校验数据Loss: 0.057579\n",
            "训练周期: 6 [10944/60000 (18%)]\t训练数据Loss: 0.060361\t校验数据Loss: 0.057918\n",
            "训练周期: 6 [17344/60000 (29%)]\t训练数据Loss: 0.060474\t校验数据Loss: 0.057787\n",
            "训练周期: 6 [23744/60000 (40%)]\t训练数据Loss: 0.060459\t校验数据Loss: 0.057740\n",
            "训练周期: 6 [30144/60000 (50%)]\t训练数据Loss: 0.060434\t校验数据Loss: 0.057317\n",
            "训练周期: 6 [36544/60000 (61%)]\t训练数据Loss: 0.060433\t校验数据Loss: 0.057574\n",
            "训练周期: 6 [42944/60000 (72%)]\t训练数据Loss: 0.060402\t校验数据Loss: 0.057907\n",
            "训练周期: 6 [49344/60000 (82%)]\t训练数据Loss: 0.060354\t校验数据Loss: 0.057110\n",
            "训练周期: 6 [55744/60000 (93%)]\t训练数据Loss: 0.060289\t校验数据Loss: 0.057400\n",
            "训练周期: 7 [2112/60000 (4%)]\t训练数据Loss: 0.059498\t校验数据Loss: 0.057407\n",
            "训练周期: 7 [8512/60000 (14%)]\t训练数据Loss: 0.060069\t校验数据Loss: 0.057274\n",
            "训练周期: 7 [14912/60000 (25%)]\t训练数据Loss: 0.059993\t校验数据Loss: 0.057518\n",
            "训练周期: 7 [21312/60000 (36%)]\t训练数据Loss: 0.059999\t校验数据Loss: 0.057161\n",
            "训练周期: 7 [27712/60000 (46%)]\t训练数据Loss: 0.060058\t校验数据Loss: 0.057562\n",
            "训练周期: 7 [34112/60000 (57%)]\t训练数据Loss: 0.060109\t校验数据Loss: 0.057459\n",
            "训练周期: 7 [40512/60000 (67%)]\t训练数据Loss: 0.060028\t校验数据Loss: 0.057122\n",
            "训练周期: 7 [46912/60000 (78%)]\t训练数据Loss: 0.060022\t校验数据Loss: 0.057304\n",
            "训练周期: 7 [53312/60000 (89%)]\t训练数据Loss: 0.060020\t校验数据Loss: 0.057365\n",
            "训练周期: 7 [59712/60000 (99%)]\t训练数据Loss: 0.060069\t校验数据Loss: 0.057642\n",
            "训练周期: 8 [6080/60000 (10%)]\t训练数据Loss: 0.060444\t校验数据Loss: 0.057318\n",
            "训练周期: 8 [12480/60000 (21%)]\t训练数据Loss: 0.060249\t校验数据Loss: 0.057535\n",
            "训练周期: 8 [18880/60000 (31%)]\t训练数据Loss: 0.060174\t校验数据Loss: 0.057586\n",
            "训练周期: 8 [25280/60000 (42%)]\t训练数据Loss: 0.060043\t校验数据Loss: 0.057404\n",
            "训练周期: 8 [31680/60000 (53%)]\t训练数据Loss: 0.059948\t校验数据Loss: 0.057202\n",
            "训练周期: 8 [38080/60000 (63%)]\t训练数据Loss: 0.059898\t校验数据Loss: 0.056878\n",
            "训练周期: 8 [44480/60000 (74%)]\t训练数据Loss: 0.059923\t校验数据Loss: 0.057498\n",
            "训练周期: 8 [50880/60000 (85%)]\t训练数据Loss: 0.059913\t校验数据Loss: 0.057013\n",
            "训练周期: 8 [57280/60000 (95%)]\t训练数据Loss: 0.059914\t校验数据Loss: 0.057444\n",
            "训练周期: 9 [3648/60000 (6%)]\t训练数据Loss: 0.059786\t校验数据Loss: 0.057301\n",
            "训练周期: 9 [10048/60000 (17%)]\t训练数据Loss: 0.059846\t校验数据Loss: 0.057108\n",
            "训练周期: 9 [16448/60000 (27%)]\t训练数据Loss: 0.059868\t校验数据Loss: 0.057091\n",
            "训练周期: 9 [22848/60000 (38%)]\t训练数据Loss: 0.059854\t校验数据Loss: 0.057253\n",
            "训练周期: 9 [29248/60000 (49%)]\t训练数据Loss: 0.059820\t校验数据Loss: 0.057282\n",
            "训练周期: 9 [35648/60000 (59%)]\t训练数据Loss: 0.059868\t校验数据Loss: 0.057550\n",
            "训练周期: 9 [42048/60000 (70%)]\t训练数据Loss: 0.059856\t校验数据Loss: 0.057207\n",
            "训练周期: 9 [48448/60000 (81%)]\t训练数据Loss: 0.059898\t校验数据Loss: 0.056790\n",
            "训练周期: 9 [54848/60000 (91%)]\t训练数据Loss: 0.059888\t校验数据Loss: 0.057167\n",
            "训练周期: 10 [1216/60000 (2%)]\t训练数据Loss: 0.059591\t校验数据Loss: 0.057444\n",
            "训练周期: 10 [7616/60000 (13%)]\t训练数据Loss: 0.059800\t校验数据Loss: 0.057436\n",
            "训练周期: 10 [14016/60000 (23%)]\t训练数据Loss: 0.059579\t校验数据Loss: 0.057072\n",
            "训练周期: 10 [20416/60000 (34%)]\t训练数据Loss: 0.059709\t校验数据Loss: 0.057192\n",
            "训练周期: 10 [26816/60000 (45%)]\t训练数据Loss: 0.059659\t校验数据Loss: 0.056962\n",
            "训练周期: 10 [33216/60000 (55%)]\t训练数据Loss: 0.059759\t校验数据Loss: 0.057465\n",
            "训练周期: 10 [39616/60000 (66%)]\t训练数据Loss: 0.059780\t校验数据Loss: 0.056938\n",
            "训练周期: 10 [46016/60000 (77%)]\t训练数据Loss: 0.059759\t校验数据Loss: 0.056919\n",
            "训练周期: 10 [52416/60000 (87%)]\t训练数据Loss: 0.059823\t校验数据Loss: 0.056729\n",
            "训练周期: 10 [58816/60000 (98%)]\t训练数据Loss: 0.059831\t校验数据Loss: 0.057136\n",
            "训练周期: 11 [5184/60000 (9%)]\t训练数据Loss: 0.059876\t校验数据Loss: 0.056916\n",
            "训练周期: 11 [11584/60000 (19%)]\t训练数据Loss: 0.060040\t校验数据Loss: 0.057185\n",
            "训练周期: 11 [17984/60000 (30%)]\t训练数据Loss: 0.059867\t校验数据Loss: 0.056768\n",
            "训练周期: 11 [24384/60000 (41%)]\t训练数据Loss: 0.059870\t校验数据Loss: 0.056990\n",
            "训练周期: 11 [30784/60000 (51%)]\t训练数据Loss: 0.059766\t校验数据Loss: 0.057178\n",
            "训练周期: 11 [37184/60000 (62%)]\t训练数据Loss: 0.059721\t校验数据Loss: 0.056692\n",
            "训练周期: 11 [43584/60000 (73%)]\t训练数据Loss: 0.059719\t校验数据Loss: 0.056593\n",
            "训练周期: 11 [49984/60000 (83%)]\t训练数据Loss: 0.059716\t校验数据Loss: 0.056680\n",
            "训练周期: 11 [56384/60000 (94%)]\t训练数据Loss: 0.059734\t校验数据Loss: 0.056968\n",
            "训练周期: 12 [2752/60000 (5%)]\t训练数据Loss: 0.059518\t校验数据Loss: 0.056949\n",
            "训练周期: 12 [9152/60000 (15%)]\t训练数据Loss: 0.059781\t校验数据Loss: 0.056647\n",
            "训练周期: 12 [15552/60000 (26%)]\t训练数据Loss: 0.059633\t校验数据Loss: 0.056754\n",
            "训练周期: 12 [21952/60000 (37%)]\t训练数据Loss: 0.059536\t校验数据Loss: 0.056975\n",
            "训练周期: 12 [28352/60000 (47%)]\t训练数据Loss: 0.059546\t校验数据Loss: 0.057221\n",
            "训练周期: 12 [34752/60000 (58%)]\t训练数据Loss: 0.059547\t校验数据Loss: 0.057099\n",
            "训练周期: 12 [41152/60000 (69%)]\t训练数据Loss: 0.059549\t校验数据Loss: 0.056596\n",
            "训练周期: 12 [47552/60000 (79%)]\t训练数据Loss: 0.059594\t校验数据Loss: 0.057141\n",
            "训练周期: 12 [53952/60000 (90%)]\t训练数据Loss: 0.059611\t校验数据Loss: 0.056545\n",
            "训练周期: 13 [320/60000 (1%)]\t训练数据Loss: 0.059646\t校验数据Loss: 0.056727\n",
            "训练周期: 13 [6720/60000 (11%)]\t训练数据Loss: 0.059345\t校验数据Loss: 0.056658\n",
            "训练周期: 13 [13120/60000 (22%)]\t训练数据Loss: 0.059463\t校验数据Loss: 0.056470\n",
            "训练周期: 13 [19520/60000 (33%)]\t训练数据Loss: 0.059470\t校验数据Loss: 0.056527\n",
            "训练周期: 13 [25920/60000 (43%)]\t训练数据Loss: 0.059498\t校验数据Loss: 0.056718\n",
            "训练周期: 13 [32320/60000 (54%)]\t训练数据Loss: 0.059533\t校验数据Loss: 0.056453\n",
            "训练周期: 13 [38720/60000 (64%)]\t训练数据Loss: 0.059489\t校验数据Loss: 0.056829\n",
            "训练周期: 13 [45120/60000 (75%)]\t训练数据Loss: 0.059544\t校验数据Loss: 0.056694\n",
            "训练周期: 13 [51520/60000 (86%)]\t训练数据Loss: 0.059523\t校验数据Loss: 0.056694\n",
            "训练周期: 13 [57920/60000 (96%)]\t训练数据Loss: 0.059534\t校验数据Loss: 0.056815\n",
            "训练周期: 14 [4288/60000 (7%)]\t训练数据Loss: 0.060162\t校验数据Loss: 0.056665\n",
            "训练周期: 14 [10688/60000 (18%)]\t训练数据Loss: 0.059759\t校验数据Loss: 0.057317\n",
            "训练周期: 14 [17088/60000 (28%)]\t训练数据Loss: 0.059716\t校验数据Loss: 0.057110\n",
            "训练周期: 14 [23488/60000 (39%)]\t训练数据Loss: 0.059679\t校验数据Loss: 0.056654\n",
            "训练周期: 14 [29888/60000 (50%)]\t训练数据Loss: 0.059553\t校验数据Loss: 0.056797\n",
            "训练周期: 14 [36288/60000 (60%)]\t训练数据Loss: 0.059461\t校验数据Loss: 0.056925\n",
            "训练周期: 14 [42688/60000 (71%)]\t训练数据Loss: 0.059471\t校验数据Loss: 0.056766\n",
            "训练周期: 14 [49088/60000 (82%)]\t训练数据Loss: 0.059466\t校验数据Loss: 0.057437\n",
            "训练周期: 14 [55488/60000 (92%)]\t训练数据Loss: 0.059460\t校验数据Loss: 0.056717\n",
            "训练周期: 15 [1856/60000 (3%)]\t训练数据Loss: 0.059685\t校验数据Loss: 0.056543\n",
            "训练周期: 15 [8256/60000 (14%)]\t训练数据Loss: 0.059627\t校验数据Loss: 0.056519\n",
            "训练周期: 15 [14656/60000 (24%)]\t训练数据Loss: 0.059496\t校验数据Loss: 0.056434\n",
            "训练周期: 15 [21056/60000 (35%)]\t训练数据Loss: 0.059500\t校验数据Loss: 0.056401\n",
            "训练周期: 15 [27456/60000 (46%)]\t训练数据Loss: 0.059338\t校验数据Loss: 0.056449\n",
            "训练周期: 15 [33856/60000 (56%)]\t训练数据Loss: 0.059318\t校验数据Loss: 0.056310\n",
            "训练周期: 15 [40256/60000 (67%)]\t训练数据Loss: 0.059372\t校验数据Loss: 0.056664\n",
            "训练周期: 15 [46656/60000 (78%)]\t训练数据Loss: 0.059344\t校验数据Loss: 0.056737\n",
            "训练周期: 15 [53056/60000 (88%)]\t训练数据Loss: 0.059382\t校验数据Loss: 0.056690\n",
            "训练周期: 15 [59456/60000 (99%)]\t训练数据Loss: 0.059399\t校验数据Loss: 0.056452\n",
            "训练周期: 16 [5824/60000 (10%)]\t训练数据Loss: 0.059206\t校验数据Loss: 0.056431\n",
            "训练周期: 16 [12224/60000 (20%)]\t训练数据Loss: 0.059125\t校验数据Loss: 0.056317\n",
            "训练周期: 16 [18624/60000 (31%)]\t训练数据Loss: 0.059466\t校验数据Loss: 0.056858\n",
            "训练周期: 16 [25024/60000 (42%)]\t训练数据Loss: 0.059544\t校验数据Loss: 0.057032\n",
            "训练周期: 16 [31424/60000 (52%)]\t训练数据Loss: 0.059431\t校验数据Loss: 0.056402\n",
            "训练周期: 16 [37824/60000 (63%)]\t训练数据Loss: 0.059366\t校验数据Loss: 0.056617\n",
            "训练周期: 16 [44224/60000 (74%)]\t训练数据Loss: 0.059307\t校验数据Loss: 0.056531\n",
            "训练周期: 16 [50624/60000 (84%)]\t训练数据Loss: 0.059363\t校验数据Loss: 0.056650\n",
            "训练周期: 16 [57024/60000 (95%)]\t训练数据Loss: 0.059380\t校验数据Loss: 0.056772\n",
            "训练周期: 17 [3392/60000 (6%)]\t训练数据Loss: 0.059144\t校验数据Loss: 0.056519\n",
            "训练周期: 17 [9792/60000 (16%)]\t训练数据Loss: 0.058987\t校验数据Loss: 0.056470\n",
            "训练周期: 17 [16192/60000 (27%)]\t训练数据Loss: 0.059036\t校验数据Loss: 0.056296\n",
            "训练周期: 17 [22592/60000 (38%)]\t训练数据Loss: 0.059042\t校验数据Loss: 0.057125\n",
            "训练周期: 17 [28992/60000 (48%)]\t训练数据Loss: 0.059203\t校验数据Loss: 0.056595\n",
            "训练周期: 17 [35392/60000 (59%)]\t训练数据Loss: 0.059275\t校验数据Loss: 0.056346\n",
            "训练周期: 17 [41792/60000 (70%)]\t训练数据Loss: 0.059291\t校验数据Loss: 0.056508\n",
            "训练周期: 17 [48192/60000 (80%)]\t训练数据Loss: 0.059334\t校验数据Loss: 0.056532\n",
            "训练周期: 17 [54592/60000 (91%)]\t训练数据Loss: 0.059327\t校验数据Loss: 0.056357\n",
            "训练周期: 18 [960/60000 (2%)]\t训练数据Loss: 0.059602\t校验数据Loss: 0.056418\n",
            "训练周期: 18 [7360/60000 (12%)]\t训练数据Loss: 0.059103\t校验数据Loss: 0.056500\n",
            "训练周期: 18 [13760/60000 (23%)]\t训练数据Loss: 0.059323\t校验数据Loss: 0.056461\n",
            "训练周期: 18 [20160/60000 (34%)]\t训练数据Loss: 0.059275\t校验数据Loss: 0.056695\n",
            "训练周期: 18 [26560/60000 (44%)]\t训练数据Loss: 0.059270\t校验数据Loss: 0.056496\n",
            "训练周期: 18 [32960/60000 (55%)]\t训练数据Loss: 0.059269\t校验数据Loss: 0.056455\n",
            "训练周期: 18 [39360/60000 (66%)]\t训练数据Loss: 0.059249\t校验数据Loss: 0.056566\n",
            "训练周期: 18 [45760/60000 (76%)]\t训练数据Loss: 0.059247\t校验数据Loss: 0.056284\n",
            "训练周期: 18 [52160/60000 (87%)]\t训练数据Loss: 0.059271\t校验数据Loss: 0.056433\n",
            "训练周期: 18 [58560/60000 (98%)]\t训练数据Loss: 0.059240\t校验数据Loss: 0.055987\n",
            "训练周期: 19 [4928/60000 (8%)]\t训练数据Loss: 0.059165\t校验数据Loss: 0.056739\n",
            "训练周期: 19 [11328/60000 (19%)]\t训练数据Loss: 0.059395\t校验数据Loss: 0.056619\n",
            "训练周期: 19 [17728/60000 (30%)]\t训练数据Loss: 0.059283\t校验数据Loss: 0.056275\n",
            "训练周期: 19 [24128/60000 (40%)]\t训练数据Loss: 0.059345\t校验数据Loss: 0.056100\n",
            "训练周期: 19 [30528/60000 (51%)]\t训练数据Loss: 0.059306\t校验数据Loss: 0.056197\n",
            "训练周期: 19 [36928/60000 (62%)]\t训练数据Loss: 0.059370\t校验数据Loss: 0.056125\n",
            "训练周期: 19 [43328/60000 (72%)]\t训练数据Loss: 0.059315\t校验数据Loss: 0.056513\n",
            "训练周期: 19 [49728/60000 (83%)]\t训练数据Loss: 0.059229\t校验数据Loss: 0.056252\n",
            "训练周期: 19 [56128/60000 (93%)]\t训练数据Loss: 0.059181\t校验数据Loss: 0.056594\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}