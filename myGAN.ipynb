{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4w6vGPpzgSj2NHbjZy2Wh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiKaChu-wcg/pytorch/blob/main/myGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VYygFHKSDVf",
        "outputId": "ee47415a-40e0-43f2-b57b-a85ab16e2453"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutil\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "# 定义超参数\n",
        "image_size = 28 #图像尺寸大小\n",
        "input_dim = 100 #输入给生成器的向量维度，维度越大可以增加生成器输出样本的多样性\n",
        "num_channels = 1# 图像的通道数\n",
        "num_features = 64 #生成器中间的卷积核数量\n",
        "batch_size = 64 #批次大小\n",
        "use_cuda=torch.cuda.is_available() \n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!mkdir data\n",
        "!tar -zxvf MNIST.tar.gz -C data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 08:20:30--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-19 08:20:31--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.2’\n",
            "\n",
            "MNIST.tar.gz.2          [         <=>        ]  33.20M  4.68MB/s    in 19s     \n",
            "\n",
            "2021-03-19 08:20:51 (1.73 MB/s) - ‘MNIST.tar.gz.2’ saved [34813078]\n",
            "\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_XjycdHbOmk"
      },
      "source": [
        "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "\n",
        "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
        "# MNIST数据是属于torchvision包自带的数据，所以可以直接调用。\n",
        "# 在调用自己的数据的时候，我们可以用torchvision.datasets.ImageFolder或者torch.utils.data.TensorDataset来加载\n",
        "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
        "                            train=True,   #提取训练集\n",
        "                            transform=transforms.ToTensor(),  #将图像转化为Tensor，在加载数据的时候，就可以对图像做预处理\n",
        "                            download=True) #当找不到文件的时候，自动下载\n",
        "\n",
        "# 加载测试数据集\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "# 训练数据集的加载器，自动将数据分割成batch，顺序随机打乱\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "'''我们希望将测试数据分成两部分，一部分作为校验数据，一部分作为测试数据。\n",
        "校验数据用于检测模型是否过拟合，并调整参数，测试数据检验整个模型的工作'''\n",
        "\n",
        "\n",
        "# 首先，我们定义下标数组indices，它相当于对所有test_dataset中数据的编码\n",
        "# 然后定义下标indices_val来表示校验集数据的那些下标，indices_test表示测试集的下标\n",
        "indices = range(len(test_dataset))\n",
        "indices_val = indices[:5000]\n",
        "indices_test = indices[5000:]\n",
        "\n",
        "# 根据这些下标，构造两个数据集的SubsetRandomSampler采样器，它会对下标进行采样\n",
        "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
        "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
        "\n",
        "# 根据两个采样器来定义加载器，注意将sampler_val和sampler_test分别赋值给了validation_loader和test_loader\n",
        "validation_loader = torch.utils.data.DataLoader(dataset =test_dataset,\n",
        "                                                batch_size = batch_size,\n",
        "                                                sampler = sampler_val\n",
        "                                               )\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          sampler = sampler_test\n",
        "                                         )\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78i98uliUdXj"
      },
      "source": [
        "class ModelD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelD,self).__init__()\n",
        "        self.model=nn.Sequential()\n",
        "        self.model.add_module('conv1',nn.Conv2d(num_channels,num_features,5,2,0,bias=False))\n",
        "        self.model.add_module('bnorm1',nn.BatchNorm2d(num_features))\n",
        "        self.model.add_module('relu1',nn.ReLU())\n",
        "        self.model.add_module('conv2',nn.Conv2d(num_features,num_features*2,5,2,0,bias=False))\n",
        "        self.model.add_module('bnorm2',nn.BatchNorm2d(num_features*2))\n",
        "        self.model.add_module('relu2',nn.ReLU())\n",
        "        self.model.add_module('linear1',nn.Linear(num_features*2*4*4,num_features))\n",
        "        self.model.add_module('linear2',nn.Linear(num_features,1))\n",
        "        self.model.add_module('sigmoid',nn.Sigmoid())\n",
        "    def forward(self,input):\n",
        "        output=input\n",
        "        for name,module in self.model.named_children():\n",
        "            if name=='linear1':\n",
        "                output=output.view(-1,num_features*2*4*4)\n",
        "            output=module(output)\n",
        "        return output\n",
        "netD=ModelD()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vV2LrdJW8-9",
        "outputId": "66a610eb-4de0-423a-da2a-2e424639e216"
      },
      "source": [
        "netD"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelD(\n",
              "  (model): Sequential(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
              "    (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU()\n",
              "    (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
              "    (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU()\n",
              "    (linear1): Linear(in_features=2048, out_features=64, bias=True)\n",
              "    (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_Jfc9wXZsG"
      },
      "source": [
        "class ModelG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelG,self).__init__()\n",
        "        self.model=nn.Sequential() #model为一个内嵌的序列化的神经网络模型\n",
        "        \n",
        "        # 利用add_module增加一个反卷积层，输入为input_dim维，输出为2*num_features维，窗口大小为5，padding是0\n",
        "        # 输入图像大小为1，输出图像大小为W'=(W-1)S-2P+K+P'=(1-1)*2-2*0+5+0=3, 5*5\n",
        "        self.model.add_module('deconv1',nn.ConvTranspose2d(input_dim, num_features*2, 5, 2, 0, bias=False))\n",
        "        # 增加一个batchnorm层\n",
        "        self.model.add_module('bnorm1',nn.BatchNorm2d(num_features*2))\n",
        "        # 增加非线性层\n",
        "        self.model.add_module('relu1',nn.ReLU(True))\n",
        "        # 增加第二层反卷积层，输入2*num_features维，输出num_features维，窗口5，padding=0\n",
        "        # 输入图像大小为5，输出图像大小为W'=(W-1)S-2P+K+P'=(5-1)*2-2*0+5+0=13, 13*13\n",
        "        self.model.add_module('deconv2',nn.ConvTranspose2d(num_features*2, num_features, 5, 2, 0, bias=False))\n",
        "        # 增加一个batchnorm层\n",
        "        self.model.add_module('bnorm2',nn.BatchNorm2d(num_features))\n",
        "        # 增加非线性层\n",
        "        self.model.add_module('relu2',nn.ReLU(True))\n",
        "\n",
        "        # 增加第二层反卷积层，输入2*num_features维，输出num_features维，窗口4，padding=0\n",
        "        # 输入图像大小为13，输出图像大小为W'=(W-1)S-2P+K+P'=(13-1)*2-2*0+4+0=28, 28*28\n",
        "        self.model.add_module('deconv3',nn.ConvTranspose2d(num_features, num_channels, 4, 2, 0,bias=False))\n",
        "        #self.model.add_module('tanh',nn.Tanh())\n",
        "        self.model.add_module('sigmoid',nn.Sigmoid())\n",
        "    def forward(self,input):\n",
        "        output = input\n",
        "        \n",
        "        #遍历网络的所有层，一层层输出信息\n",
        "        for name, module in self.model.named_children():\n",
        "            output = module(output)\n",
        "        #输出一张28*28的图像\n",
        "        return(output)\n",
        "netG=ModelG()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MtVYMXzXfnK",
        "outputId": "53459106-618e-4d93-92b7-3d577cf9b319"
      },
      "source": [
        "netG"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelG(\n",
              "  (model): Sequential(\n",
              "    (deconv1): ConvTranspose2d(100, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
              "    (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (deconv2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
              "    (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (deconv3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzvWonrwXhPZ"
      },
      "source": [
        "def weight_init(m):\n",
        "    #模型参数初始化．\n",
        "    #默认的初始化参数卷积核的权重是均值大概为0，方差在10^{-2}. BatchNorm层的权重均值是大约0.5，方差在0.2左右\n",
        "    #使用如下初始化方式可以，可以让方差更小，使得收敛更快\n",
        "    class_name=m.__class__.__name__\n",
        "    if class_name.find('conv')!=-1:\n",
        "        m.weight.data.normal_(0,0.02)\n",
        "    if class_name.find('norm')!=-1:\n",
        "        m.weight.data.normal_(1.0,0.02)\n",
        "def make_show(img):\n",
        "    # 将张量变成可以显示的图像\n",
        "    img = img.data.expand(batch_size, 3, image_size, image_size)\n",
        "    return img\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    # 在屏幕上绘制图像\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if inp.size()[0] > 1:\n",
        "        inp = inp.numpy().transpose((1, 2, 0))\n",
        "    else:\n",
        "        inp = inp[0].numpy()\n",
        "    mvalue = np.amin(inp)\n",
        "    maxvalue = np.amax(inp)\n",
        "    if maxvalue > mvalue:\n",
        "        inp = (inp - mvalue)/(maxvalue - mvalue)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8rHvNAjXvuP"
      },
      "source": [
        "netD.apply(weight_init)\n",
        "netG.apply(weight_init)\n",
        "netD=netD.cuda() if use_cuda else netD\n",
        "netG=netG.cuda() if use_cuda else netG\n",
        "optimizerD=optim.Adam(netD.parameters(),lr=0.0005,betas=(0.5,0.999))\n",
        "optimizerG=optim.Adam(netG.parameters(),lr=0.0005,betas=(0.5,0.999))\n",
        "noise=torch.tensor((batch_size,input_dim,1,1),dtype=torch.float)\n",
        "fixed_noise=torch.FloatTensor(batch_size,input_dim,1,1,).normal_(0,1).requires_grad_(True)\n",
        "if use_cuda:\n",
        "    noise=noise.cuda()\n",
        "    fixed_noise=fixed_noise.cuda()\n",
        "criterion=nn.BCELoss()\n",
        "error_G=None\n",
        "num_epochs=50\n",
        "result=[]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FNnvWN2ZaXd",
        "outputId": "3ccbee57-8eb2-472b-c764-e36f7688fc2d"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch_idx,(data,target) in enumerate(train_loader):\n",
        "        optimizerD.zero_grad()\n",
        "        data,target=data.clone().detach().requires_grad_(True),target.clone().detach()\n",
        "        label=torch.ones(data.size()[0],1)\n",
        "        if use_cuda:\n",
        "            data,target,label=data.cuda(),target.cuda(),label.cuda()\n",
        "        netD.train()\n",
        "        output=netD(data)\n",
        "        label.data.fill_(1)\n",
        "        error_real=criterion(output,label)\n",
        "        error_real.backward()\n",
        "        D_x=output.data.mean()\n",
        "        with torch.no_grad():\n",
        "            noise.resize_(data.size()[0],input_dim,1,1).normal_(0,1)\n",
        "        fake_pic=netG(noise).detach()\n",
        "        output2=netD(fake_pic)\n",
        "        label.data.fill_(0)\n",
        "        error_fake=criterion(output2,label)\n",
        "        error_fake.backward()\n",
        "        error_D=error_real+error_fake\n",
        "        optimizerD.step()\n",
        "        if error_G is None or np.random.rand()<0.5:\n",
        "            optimizerG.zero_grad()\n",
        "            label.data.fill_(1)\n",
        "            noise.data.normal_(0,1)\n",
        "            netG.train()\n",
        "            fake_pic=netG(noise)\n",
        "            output=netD(fake_pic)\n",
        "            error_G=criterion(output,label)\n",
        "            error_G.backward()\n",
        "            optimizerG.step()\n",
        "        if use_cuda:\n",
        "            error_D=error_D.cpu()\n",
        "            error_G=error_G.cpu()\n",
        "        result.append([float(error_D.data.numpy()),float(error_G.data.numpy())])\n",
        "        if batch_idx % 100 == 0:\n",
        "            print ('第{}周期，第{}/{}撮, 分类器Loss:{:.2f}, 生成器Loss:{:.2f}'.format(\n",
        "                epoch,batch_idx,len(train_loader),\n",
        "                error_D.data.item(), \n",
        "                error_G.data.item()))        \n",
        "    netG.eval()\n",
        "    fake_u=netG(fixed_noise)\n",
        "    fake_u = fake_u.cpu() if use_cuda else fake_u\n",
        "    img = make_show(fake_u)\n",
        "\n",
        "    #挑选一些真实数据中的图像图像保存\n",
        "    data, _ = next(iter(train_loader))\n",
        "    os.makedirs('temp',exist_ok=True)\n",
        "    os.makedirs('net',exist_ok=True)\n",
        "    vutil.save_image(img,'temp/fake%s.png'% (epoch))\n",
        "    # 保存网络状态到硬盘文件\n",
        "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % ('net', epoch))\n",
        "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % ('net', epoch))\n",
        "    if epoch == 0:\n",
        "        img = make_show(data.clone().detach().requires_grad_(True))\n",
        "        vutil.save_image(img,'temp/real%s.png' % (epoch))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "第0周期，第0/938撮, 分类器Loss:0.00, 生成器Loss:30.65\n",
            "第0周期，第100/938撮, 分类器Loss:0.50, 生成器Loss:6.22\n",
            "第0周期，第200/938撮, 分类器Loss:0.98, 生成器Loss:4.19\n",
            "第0周期，第300/938撮, 分类器Loss:0.60, 生成器Loss:3.42\n",
            "第0周期，第400/938撮, 分类器Loss:0.29, 生成器Loss:4.03\n",
            "第0周期，第500/938撮, 分类器Loss:0.17, 生成器Loss:2.34\n",
            "第0周期，第600/938撮, 分类器Loss:0.08, 生成器Loss:3.83\n",
            "第0周期，第700/938撮, 分类器Loss:0.37, 生成器Loss:2.64\n",
            "第0周期，第800/938撮, 分类器Loss:0.14, 生成器Loss:4.41\n",
            "第0周期，第900/938撮, 分类器Loss:0.22, 生成器Loss:5.17\n",
            "第1周期，第0/938撮, 分类器Loss:0.06, 生成器Loss:5.37\n",
            "第1周期，第100/938撮, 分类器Loss:0.16, 生成器Loss:4.01\n",
            "第1周期，第200/938撮, 分类器Loss:0.13, 生成器Loss:4.83\n",
            "第1周期，第300/938撮, 分类器Loss:0.55, 生成器Loss:2.92\n",
            "第1周期，第400/938撮, 分类器Loss:0.06, 生成器Loss:3.34\n",
            "第1周期，第500/938撮, 分类器Loss:0.33, 生成器Loss:7.79\n",
            "第1周期，第600/938撮, 分类器Loss:0.27, 生成器Loss:6.18\n",
            "第1周期，第700/938撮, 分类器Loss:0.17, 生成器Loss:4.72\n",
            "第1周期，第800/938撮, 分类器Loss:0.11, 生成器Loss:6.67\n",
            "第1周期，第900/938撮, 分类器Loss:0.47, 生成器Loss:3.04\n",
            "第2周期，第0/938撮, 分类器Loss:0.16, 生成器Loss:5.52\n",
            "第2周期，第100/938撮, 分类器Loss:0.41, 生成器Loss:2.30\n",
            "第2周期，第200/938撮, 分类器Loss:0.05, 生成器Loss:4.64\n",
            "第2周期，第300/938撮, 分类器Loss:0.08, 生成器Loss:5.76\n",
            "第2周期，第400/938撮, 分类器Loss:0.08, 生成器Loss:6.03\n",
            "第2周期，第500/938撮, 分类器Loss:0.12, 生成器Loss:4.81\n",
            "第2周期，第600/938撮, 分类器Loss:0.63, 生成器Loss:4.93\n",
            "第2周期，第700/938撮, 分类器Loss:0.09, 生成器Loss:5.31\n",
            "第2周期，第800/938撮, 分类器Loss:0.09, 生成器Loss:4.58\n",
            "第2周期，第900/938撮, 分类器Loss:0.56, 生成器Loss:4.43\n",
            "第3周期，第0/938撮, 分类器Loss:0.15, 生成器Loss:4.51\n",
            "第3周期，第100/938撮, 分类器Loss:0.12, 生成器Loss:4.87\n",
            "第3周期，第200/938撮, 分类器Loss:0.08, 生成器Loss:5.60\n",
            "第3周期，第300/938撮, 分类器Loss:0.13, 生成器Loss:5.50\n",
            "第3周期，第400/938撮, 分类器Loss:0.20, 生成器Loss:6.41\n",
            "第3周期，第500/938撮, 分类器Loss:0.17, 生成器Loss:5.24\n",
            "第3周期，第600/938撮, 分类器Loss:0.18, 生成器Loss:2.91\n",
            "第3周期，第700/938撮, 分类器Loss:0.16, 生成器Loss:2.96\n",
            "第3周期，第800/938撮, 分类器Loss:0.41, 生成器Loss:6.51\n",
            "第3周期，第900/938撮, 分类器Loss:0.28, 生成器Loss:4.90\n",
            "第4周期，第0/938撮, 分类器Loss:0.29, 生成器Loss:6.70\n",
            "第4周期，第100/938撮, 分类器Loss:0.07, 生成器Loss:7.76\n",
            "第4周期，第200/938撮, 分类器Loss:0.15, 生成器Loss:4.03\n",
            "第4周期，第300/938撮, 分类器Loss:0.16, 生成器Loss:5.15\n",
            "第4周期，第400/938撮, 分类器Loss:0.06, 生成器Loss:7.02\n",
            "第4周期，第500/938撮, 分类器Loss:0.36, 生成器Loss:7.57\n",
            "第4周期，第600/938撮, 分类器Loss:0.22, 生成器Loss:4.03\n",
            "第4周期，第700/938撮, 分类器Loss:0.28, 生成器Loss:5.71\n",
            "第4周期，第800/938撮, 分类器Loss:0.19, 生成器Loss:3.37\n",
            "第4周期，第900/938撮, 分类器Loss:0.14, 生成器Loss:6.17\n",
            "第5周期，第0/938撮, 分类器Loss:1.00, 生成器Loss:3.11\n",
            "第5周期，第100/938撮, 分类器Loss:0.27, 生成器Loss:5.32\n",
            "第5周期，第200/938撮, 分类器Loss:0.10, 生成器Loss:6.46\n",
            "第5周期，第300/938撮, 分类器Loss:0.19, 生成器Loss:3.90\n",
            "第5周期，第400/938撮, 分类器Loss:0.27, 生成器Loss:4.97\n",
            "第5周期，第500/938撮, 分类器Loss:0.24, 生成器Loss:3.65\n",
            "第5周期，第600/938撮, 分类器Loss:0.59, 生成器Loss:7.28\n",
            "第5周期，第700/938撮, 分类器Loss:0.25, 生成器Loss:4.57\n",
            "第5周期，第800/938撮, 分类器Loss:0.15, 生成器Loss:5.91\n",
            "第5周期，第900/938撮, 分类器Loss:0.31, 生成器Loss:5.88\n",
            "第6周期，第0/938撮, 分类器Loss:0.12, 生成器Loss:5.23\n",
            "第6周期，第100/938撮, 分类器Loss:0.37, 生成器Loss:7.24\n",
            "第6周期，第200/938撮, 分类器Loss:0.38, 生成器Loss:3.83\n",
            "第6周期，第300/938撮, 分类器Loss:0.22, 生成器Loss:3.97\n",
            "第6周期，第400/938撮, 分类器Loss:0.24, 生成器Loss:3.80\n",
            "第6周期，第500/938撮, 分类器Loss:0.08, 生成器Loss:5.47\n",
            "第6周期，第600/938撮, 分类器Loss:0.31, 生成器Loss:3.96\n",
            "第6周期，第700/938撮, 分类器Loss:0.14, 生成器Loss:5.17\n",
            "第6周期，第800/938撮, 分类器Loss:0.26, 生成器Loss:5.62\n",
            "第6周期，第900/938撮, 分类器Loss:0.48, 生成器Loss:4.98\n",
            "第7周期，第0/938撮, 分类器Loss:0.23, 生成器Loss:3.20\n",
            "第7周期，第100/938撮, 分类器Loss:0.28, 生成器Loss:2.30\n",
            "第7周期，第200/938撮, 分类器Loss:0.28, 生成器Loss:5.63\n",
            "第7周期，第300/938撮, 分类器Loss:0.12, 生成器Loss:3.98\n",
            "第7周期，第400/938撮, 分类器Loss:0.61, 生成器Loss:3.52\n",
            "第7周期，第500/938撮, 分类器Loss:0.22, 生成器Loss:4.24\n",
            "第7周期，第600/938撮, 分类器Loss:0.43, 生成器Loss:5.90\n",
            "第7周期，第700/938撮, 分类器Loss:0.37, 生成器Loss:3.65\n",
            "第7周期，第800/938撮, 分类器Loss:0.28, 生成器Loss:5.85\n",
            "第7周期，第900/938撮, 分类器Loss:0.17, 生成器Loss:3.55\n",
            "第8周期，第0/938撮, 分类器Loss:0.24, 生成器Loss:5.45\n",
            "第8周期，第100/938撮, 分类器Loss:0.13, 生成器Loss:7.28\n",
            "第8周期，第200/938撮, 分类器Loss:0.31, 生成器Loss:5.07\n",
            "第8周期，第300/938撮, 分类器Loss:0.14, 生成器Loss:3.55\n",
            "第8周期，第400/938撮, 分类器Loss:0.17, 生成器Loss:4.33\n",
            "第8周期，第500/938撮, 分类器Loss:0.69, 生成器Loss:7.72\n",
            "第8周期，第600/938撮, 分类器Loss:0.18, 生成器Loss:5.48\n",
            "第8周期，第700/938撮, 分类器Loss:0.33, 生成器Loss:6.79\n",
            "第8周期，第800/938撮, 分类器Loss:0.35, 生成器Loss:3.44\n",
            "第8周期，第900/938撮, 分类器Loss:0.64, 生成器Loss:5.95\n",
            "第9周期，第0/938撮, 分类器Loss:0.34, 生成器Loss:4.66\n",
            "第9周期，第100/938撮, 分类器Loss:0.15, 生成器Loss:6.28\n",
            "第9周期，第200/938撮, 分类器Loss:0.18, 生成器Loss:6.27\n",
            "第9周期，第300/938撮, 分类器Loss:0.29, 生成器Loss:4.88\n",
            "第9周期，第400/938撮, 分类器Loss:0.37, 生成器Loss:6.92\n",
            "第9周期，第500/938撮, 分类器Loss:0.52, 生成器Loss:5.54\n",
            "第9周期，第600/938撮, 分类器Loss:0.24, 生成器Loss:3.30\n",
            "第9周期，第700/938撮, 分类器Loss:0.16, 生成器Loss:5.25\n",
            "第9周期，第800/938撮, 分类器Loss:0.34, 生成器Loss:3.93\n",
            "第9周期，第900/938撮, 分类器Loss:0.84, 生成器Loss:1.71\n",
            "第10周期，第0/938撮, 分类器Loss:0.87, 生成器Loss:2.19\n",
            "第10周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:3.80\n",
            "第10周期，第200/938撮, 分类器Loss:0.41, 生成器Loss:6.75\n",
            "第10周期，第300/938撮, 分类器Loss:0.69, 生成器Loss:4.96\n",
            "第10周期，第400/938撮, 分类器Loss:0.28, 生成器Loss:5.78\n",
            "第10周期，第500/938撮, 分类器Loss:0.29, 生成器Loss:5.09\n",
            "第10周期，第600/938撮, 分类器Loss:0.25, 生成器Loss:4.48\n",
            "第10周期，第700/938撮, 分类器Loss:0.96, 生成器Loss:1.58\n",
            "第10周期，第800/938撮, 分类器Loss:0.31, 生成器Loss:3.27\n",
            "第10周期，第900/938撮, 分类器Loss:0.18, 生成器Loss:4.51\n",
            "第11周期，第0/938撮, 分类器Loss:0.12, 生成器Loss:4.72\n",
            "第11周期，第100/938撮, 分类器Loss:0.34, 生成器Loss:3.19\n",
            "第11周期，第200/938撮, 分类器Loss:0.30, 生成器Loss:3.87\n",
            "第11周期，第300/938撮, 分类器Loss:0.28, 生成器Loss:9.85\n",
            "第11周期，第400/938撮, 分类器Loss:0.35, 生成器Loss:4.41\n",
            "第11周期，第500/938撮, 分类器Loss:0.25, 生成器Loss:4.97\n",
            "第11周期，第600/938撮, 分类器Loss:0.26, 生成器Loss:4.09\n",
            "第11周期，第700/938撮, 分类器Loss:0.18, 生成器Loss:3.18\n",
            "第11周期，第800/938撮, 分类器Loss:0.67, 生成器Loss:5.32\n",
            "第11周期，第900/938撮, 分类器Loss:0.21, 生成器Loss:4.90\n",
            "第12周期，第0/938撮, 分类器Loss:0.79, 生成器Loss:7.43\n",
            "第12周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:6.74\n",
            "第12周期，第200/938撮, 分类器Loss:0.27, 生成器Loss:4.83\n",
            "第12周期，第300/938撮, 分类器Loss:0.28, 生成器Loss:7.08\n",
            "第12周期，第400/938撮, 分类器Loss:0.27, 生成器Loss:5.45\n",
            "第12周期，第500/938撮, 分类器Loss:0.28, 生成器Loss:3.33\n",
            "第12周期，第600/938撮, 分类器Loss:0.51, 生成器Loss:4.91\n",
            "第12周期，第700/938撮, 分类器Loss:0.36, 生成器Loss:4.50\n",
            "第12周期，第800/938撮, 分类器Loss:0.13, 生成器Loss:5.09\n",
            "第12周期，第900/938撮, 分类器Loss:0.19, 生成器Loss:5.75\n",
            "第13周期，第0/938撮, 分类器Loss:0.14, 生成器Loss:4.72\n",
            "第13周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:6.55\n",
            "第13周期，第200/938撮, 分类器Loss:0.12, 生成器Loss:5.05\n",
            "第13周期，第300/938撮, 分类器Loss:0.19, 生成器Loss:4.35\n",
            "第13周期，第400/938撮, 分类器Loss:0.21, 生成器Loss:3.85\n",
            "第13周期，第500/938撮, 分类器Loss:0.47, 生成器Loss:2.36\n",
            "第13周期，第600/938撮, 分类器Loss:0.36, 生成器Loss:3.66\n",
            "第13周期，第700/938撮, 分类器Loss:0.33, 生成器Loss:5.52\n",
            "第13周期，第800/938撮, 分类器Loss:0.34, 生成器Loss:3.92\n",
            "第13周期，第900/938撮, 分类器Loss:0.20, 生成器Loss:3.69\n",
            "第14周期，第0/938撮, 分类器Loss:0.27, 生成器Loss:4.46\n",
            "第14周期，第100/938撮, 分类器Loss:0.39, 生成器Loss:4.69\n",
            "第14周期，第200/938撮, 分类器Loss:0.38, 生成器Loss:4.81\n",
            "第14周期，第300/938撮, 分类器Loss:0.17, 生成器Loss:2.78\n",
            "第14周期，第400/938撮, 分类器Loss:0.23, 生成器Loss:4.95\n",
            "第14周期，第500/938撮, 分类器Loss:0.10, 生成器Loss:4.03\n",
            "第14周期，第600/938撮, 分类器Loss:0.61, 生成器Loss:6.05\n",
            "第14周期，第700/938撮, 分类器Loss:0.23, 生成器Loss:5.34\n",
            "第14周期，第800/938撮, 分类器Loss:0.62, 生成器Loss:2.75\n",
            "第14周期，第900/938撮, 分类器Loss:0.22, 生成器Loss:4.34\n",
            "第15周期，第0/938撮, 分类器Loss:0.35, 生成器Loss:4.90\n",
            "第15周期，第100/938撮, 分类器Loss:0.34, 生成器Loss:6.24\n",
            "第15周期，第200/938撮, 分类器Loss:0.20, 生成器Loss:6.04\n",
            "第15周期，第300/938撮, 分类器Loss:0.28, 生成器Loss:5.04\n",
            "第15周期，第400/938撮, 分类器Loss:0.62, 生成器Loss:4.62\n",
            "第15周期，第500/938撮, 分类器Loss:0.23, 生成器Loss:4.97\n",
            "第15周期，第600/938撮, 分类器Loss:0.37, 生成器Loss:6.14\n",
            "第15周期，第700/938撮, 分类器Loss:0.12, 生成器Loss:6.53\n",
            "第15周期，第800/938撮, 分类器Loss:0.16, 生成器Loss:2.75\n",
            "第15周期，第900/938撮, 分类器Loss:0.36, 生成器Loss:5.16\n",
            "第16周期，第0/938撮, 分类器Loss:0.16, 生成器Loss:4.42\n",
            "第16周期，第100/938撮, 分类器Loss:0.15, 生成器Loss:5.88\n",
            "第16周期，第200/938撮, 分类器Loss:0.36, 生成器Loss:5.11\n",
            "第16周期，第300/938撮, 分类器Loss:0.21, 生成器Loss:5.23\n",
            "第16周期，第400/938撮, 分类器Loss:0.10, 生成器Loss:5.90\n",
            "第16周期，第500/938撮, 分类器Loss:0.10, 生成器Loss:5.65\n",
            "第16周期，第600/938撮, 分类器Loss:0.33, 生成器Loss:3.82\n",
            "第16周期，第700/938撮, 分类器Loss:0.31, 生成器Loss:5.03\n",
            "第16周期，第800/938撮, 分类器Loss:0.26, 生成器Loss:6.81\n",
            "第16周期，第900/938撮, 分类器Loss:0.24, 生成器Loss:4.28\n",
            "第17周期，第0/938撮, 分类器Loss:0.16, 生成器Loss:4.57\n",
            "第17周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:3.90\n",
            "第17周期，第200/938撮, 分类器Loss:0.18, 生成器Loss:4.86\n",
            "第17周期，第300/938撮, 分类器Loss:0.43, 生成器Loss:3.41\n",
            "第17周期，第400/938撮, 分类器Loss:0.41, 生成器Loss:2.75\n",
            "第17周期，第500/938撮, 分类器Loss:0.16, 生成器Loss:5.44\n",
            "第17周期，第600/938撮, 分类器Loss:0.38, 生成器Loss:8.40\n",
            "第17周期，第700/938撮, 分类器Loss:0.09, 生成器Loss:5.64\n",
            "第17周期，第800/938撮, 分类器Loss:0.53, 生成器Loss:3.46\n",
            "第17周期，第900/938撮, 分类器Loss:0.33, 生成器Loss:5.55\n",
            "第18周期，第0/938撮, 分类器Loss:0.62, 生成器Loss:2.61\n",
            "第18周期，第100/938撮, 分类器Loss:0.23, 生成器Loss:5.02\n",
            "第18周期，第200/938撮, 分类器Loss:0.53, 生成器Loss:2.65\n",
            "第18周期，第300/938撮, 分类器Loss:0.93, 生成器Loss:2.24\n",
            "第18周期，第400/938撮, 分类器Loss:0.24, 生成器Loss:4.56\n",
            "第18周期，第500/938撮, 分类器Loss:0.58, 生成器Loss:3.22\n",
            "第18周期，第600/938撮, 分类器Loss:0.20, 生成器Loss:5.33\n",
            "第18周期，第700/938撮, 分类器Loss:0.29, 生成器Loss:5.38\n",
            "第18周期，第800/938撮, 分类器Loss:0.10, 生成器Loss:8.00\n",
            "第18周期，第900/938撮, 分类器Loss:0.11, 生成器Loss:4.25\n",
            "第19周期，第0/938撮, 分类器Loss:0.21, 生成器Loss:4.95\n",
            "第19周期，第100/938撮, 分类器Loss:0.21, 生成器Loss:5.56\n",
            "第19周期，第200/938撮, 分类器Loss:0.14, 生成器Loss:4.81\n",
            "第19周期，第300/938撮, 分类器Loss:0.17, 生成器Loss:5.77\n",
            "第19周期，第400/938撮, 分类器Loss:0.60, 生成器Loss:6.42\n",
            "第19周期，第500/938撮, 分类器Loss:0.28, 生成器Loss:4.87\n",
            "第19周期，第600/938撮, 分类器Loss:0.13, 生成器Loss:7.06\n",
            "第19周期，第700/938撮, 分类器Loss:0.39, 生成器Loss:3.31\n",
            "第19周期，第800/938撮, 分类器Loss:0.17, 生成器Loss:1.67\n",
            "第19周期，第900/938撮, 分类器Loss:0.21, 生成器Loss:4.56\n",
            "第20周期，第0/938撮, 分类器Loss:0.17, 生成器Loss:4.51\n",
            "第20周期，第100/938撮, 分类器Loss:0.74, 生成器Loss:7.75\n",
            "第20周期，第200/938撮, 分类器Loss:0.57, 生成器Loss:2.59\n",
            "第20周期，第300/938撮, 分类器Loss:0.19, 生成器Loss:2.27\n",
            "第20周期，第400/938撮, 分类器Loss:0.38, 生成器Loss:4.64\n",
            "第20周期，第500/938撮, 分类器Loss:0.14, 生成器Loss:3.60\n",
            "第20周期，第600/938撮, 分类器Loss:0.24, 生成器Loss:5.23\n",
            "第20周期，第700/938撮, 分类器Loss:0.06, 生成器Loss:3.48\n",
            "第20周期，第800/938撮, 分类器Loss:0.27, 生成器Loss:5.82\n",
            "第20周期，第900/938撮, 分类器Loss:0.07, 生成器Loss:4.32\n",
            "第21周期，第0/938撮, 分类器Loss:0.11, 生成器Loss:5.60\n",
            "第21周期，第100/938撮, 分类器Loss:0.21, 生成器Loss:5.42\n",
            "第21周期，第200/938撮, 分类器Loss:0.62, 生成器Loss:5.66\n",
            "第21周期，第300/938撮, 分类器Loss:0.18, 生成器Loss:5.21\n",
            "第21周期，第400/938撮, 分类器Loss:0.65, 生成器Loss:7.24\n",
            "第21周期，第500/938撮, 分类器Loss:0.30, 生成器Loss:4.98\n",
            "第21周期，第600/938撮, 分类器Loss:0.28, 生成器Loss:3.03\n",
            "第21周期，第700/938撮, 分类器Loss:0.56, 生成器Loss:5.96\n",
            "第21周期，第800/938撮, 分类器Loss:0.35, 生成器Loss:6.67\n",
            "第21周期，第900/938撮, 分类器Loss:0.23, 生成器Loss:3.41\n",
            "第22周期，第0/938撮, 分类器Loss:0.21, 生成器Loss:7.35\n",
            "第22周期，第100/938撮, 分类器Loss:0.13, 生成器Loss:5.44\n",
            "第22周期，第200/938撮, 分类器Loss:0.47, 生成器Loss:5.69\n",
            "第22周期，第300/938撮, 分类器Loss:0.29, 生成器Loss:4.66\n",
            "第22周期，第400/938撮, 分类器Loss:0.25, 生成器Loss:5.79\n",
            "第22周期，第500/938撮, 分类器Loss:0.25, 生成器Loss:3.68\n",
            "第22周期，第600/938撮, 分类器Loss:0.05, 生成器Loss:4.55\n",
            "第22周期，第700/938撮, 分类器Loss:0.45, 生成器Loss:2.91\n",
            "第22周期，第800/938撮, 分类器Loss:0.16, 生成器Loss:6.46\n",
            "第22周期，第900/938撮, 分类器Loss:0.22, 生成器Loss:3.50\n",
            "第23周期，第0/938撮, 分类器Loss:0.33, 生成器Loss:4.57\n",
            "第23周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:5.44\n",
            "第23周期，第200/938撮, 分类器Loss:0.32, 生成器Loss:7.70\n",
            "第23周期，第300/938撮, 分类器Loss:0.48, 生成器Loss:8.28\n",
            "第23周期，第400/938撮, 分类器Loss:0.29, 生成器Loss:4.07\n",
            "第23周期，第500/938撮, 分类器Loss:0.28, 生成器Loss:4.34\n",
            "第23周期，第600/938撮, 分类器Loss:0.31, 生成器Loss:6.94\n",
            "第23周期，第700/938撮, 分类器Loss:0.23, 生成器Loss:6.23\n",
            "第23周期，第800/938撮, 分类器Loss:0.18, 生成器Loss:5.76\n",
            "第23周期，第900/938撮, 分类器Loss:0.22, 生成器Loss:4.48\n",
            "第24周期，第0/938撮, 分类器Loss:0.27, 生成器Loss:6.45\n",
            "第24周期，第100/938撮, 分类器Loss:0.55, 生成器Loss:3.73\n",
            "第24周期，第200/938撮, 分类器Loss:0.29, 生成器Loss:5.69\n",
            "第24周期，第300/938撮, 分类器Loss:0.92, 生成器Loss:2.52\n",
            "第24周期，第400/938撮, 分类器Loss:0.52, 生成器Loss:6.90\n",
            "第24周期，第500/938撮, 分类器Loss:0.34, 生成器Loss:6.62\n",
            "第24周期，第600/938撮, 分类器Loss:0.38, 生成器Loss:4.42\n",
            "第24周期，第700/938撮, 分类器Loss:0.32, 生成器Loss:4.25\n",
            "第24周期，第800/938撮, 分类器Loss:0.19, 生成器Loss:4.72\n",
            "第24周期，第900/938撮, 分类器Loss:0.14, 生成器Loss:5.71\n",
            "第25周期，第0/938撮, 分类器Loss:0.20, 生成器Loss:5.05\n",
            "第25周期，第100/938撮, 分类器Loss:0.27, 生成器Loss:5.11\n",
            "第25周期，第200/938撮, 分类器Loss:0.19, 生成器Loss:6.21\n",
            "第25周期，第300/938撮, 分类器Loss:0.23, 生成器Loss:6.14\n",
            "第25周期，第400/938撮, 分类器Loss:0.25, 生成器Loss:5.58\n",
            "第25周期，第500/938撮, 分类器Loss:0.35, 生成器Loss:5.20\n",
            "第25周期，第600/938撮, 分类器Loss:0.25, 生成器Loss:7.11\n",
            "第25周期，第700/938撮, 分类器Loss:0.12, 生成器Loss:4.80\n",
            "第25周期，第800/938撮, 分类器Loss:0.22, 生成器Loss:3.12\n",
            "第25周期，第900/938撮, 分类器Loss:0.20, 生成器Loss:5.68\n",
            "第26周期，第0/938撮, 分类器Loss:2.30, 生成器Loss:0.49\n",
            "第26周期，第100/938撮, 分类器Loss:0.20, 生成器Loss:3.78\n",
            "第26周期，第200/938撮, 分类器Loss:1.39, 生成器Loss:3.21\n",
            "第26周期，第300/938撮, 分类器Loss:0.15, 生成器Loss:5.47\n",
            "第26周期，第400/938撮, 分类器Loss:0.21, 生成器Loss:7.96\n",
            "第26周期，第500/938撮, 分类器Loss:0.10, 生成器Loss:5.74\n",
            "第26周期，第600/938撮, 分类器Loss:0.19, 生成器Loss:4.80\n",
            "第26周期，第700/938撮, 分类器Loss:0.12, 生成器Loss:10.00\n",
            "第26周期，第800/938撮, 分类器Loss:0.17, 生成器Loss:6.97\n",
            "第26周期，第900/938撮, 分类器Loss:0.96, 生成器Loss:6.72\n",
            "第27周期，第0/938撮, 分类器Loss:0.29, 生成器Loss:9.36\n",
            "第27周期，第100/938撮, 分类器Loss:0.06, 生成器Loss:6.57\n",
            "第27周期，第200/938撮, 分类器Loss:0.31, 生成器Loss:6.42\n",
            "第27周期，第300/938撮, 分类器Loss:0.13, 生成器Loss:4.80\n",
            "第27周期，第400/938撮, 分类器Loss:0.68, 生成器Loss:4.13\n",
            "第27周期，第500/938撮, 分类器Loss:0.60, 生成器Loss:4.37\n",
            "第27周期，第600/938撮, 分类器Loss:1.26, 生成器Loss:1.53\n",
            "第27周期，第700/938撮, 分类器Loss:0.24, 生成器Loss:6.87\n",
            "第27周期，第800/938撮, 分类器Loss:0.48, 生成器Loss:6.90\n",
            "第27周期，第900/938撮, 分类器Loss:0.08, 生成器Loss:4.89\n",
            "第28周期，第0/938撮, 分类器Loss:0.11, 生成器Loss:6.78\n",
            "第28周期，第100/938撮, 分类器Loss:0.36, 生成器Loss:5.96\n",
            "第28周期，第200/938撮, 分类器Loss:0.28, 生成器Loss:3.98\n",
            "第28周期，第300/938撮, 分类器Loss:0.15, 生成器Loss:7.16\n",
            "第28周期，第400/938撮, 分类器Loss:0.43, 生成器Loss:2.60\n",
            "第28周期，第500/938撮, 分类器Loss:0.08, 生成器Loss:5.53\n",
            "第28周期，第600/938撮, 分类器Loss:0.09, 生成器Loss:7.10\n",
            "第28周期，第700/938撮, 分类器Loss:0.29, 生成器Loss:5.76\n",
            "第28周期，第800/938撮, 分类器Loss:0.31, 生成器Loss:3.60\n",
            "第28周期，第900/938撮, 分类器Loss:0.39, 生成器Loss:4.53\n",
            "第29周期，第0/938撮, 分类器Loss:0.20, 生成器Loss:5.66\n",
            "第29周期，第100/938撮, 分类器Loss:0.29, 生成器Loss:4.94\n",
            "第29周期，第200/938撮, 分类器Loss:0.56, 生成器Loss:5.94\n",
            "第29周期，第300/938撮, 分类器Loss:0.33, 生成器Loss:5.84\n",
            "第29周期，第400/938撮, 分类器Loss:0.26, 生成器Loss:4.97\n",
            "第29周期，第500/938撮, 分类器Loss:0.40, 生成器Loss:3.33\n",
            "第29周期，第600/938撮, 分类器Loss:0.16, 生成器Loss:8.03\n",
            "第29周期，第700/938撮, 分类器Loss:0.24, 生成器Loss:5.35\n",
            "第29周期，第800/938撮, 分类器Loss:0.33, 生成器Loss:6.54\n",
            "第29周期，第900/938撮, 分类器Loss:0.33, 生成器Loss:7.31\n",
            "第30周期，第0/938撮, 分类器Loss:0.16, 生成器Loss:7.81\n",
            "第30周期，第100/938撮, 分类器Loss:0.12, 生成器Loss:6.06\n",
            "第30周期，第200/938撮, 分类器Loss:0.13, 生成器Loss:8.78\n",
            "第30周期，第300/938撮, 分类器Loss:0.11, 生成器Loss:4.86\n",
            "第30周期，第400/938撮, 分类器Loss:0.19, 生成器Loss:9.69\n",
            "第30周期，第500/938撮, 分类器Loss:0.13, 生成器Loss:5.91\n",
            "第30周期，第600/938撮, 分类器Loss:0.22, 生成器Loss:3.85\n",
            "第30周期，第700/938撮, 分类器Loss:0.12, 生成器Loss:4.51\n",
            "第30周期，第800/938撮, 分类器Loss:0.37, 生成器Loss:4.23\n",
            "第30周期，第900/938撮, 分类器Loss:0.09, 生成器Loss:5.62\n",
            "第31周期，第0/938撮, 分类器Loss:1.15, 生成器Loss:1.62\n",
            "第31周期，第100/938撮, 分类器Loss:0.50, 生成器Loss:4.44\n",
            "第31周期，第200/938撮, 分类器Loss:0.53, 生成器Loss:6.24\n",
            "第31周期，第300/938撮, 分类器Loss:0.08, 生成器Loss:3.32\n",
            "第31周期，第400/938撮, 分类器Loss:0.43, 生成器Loss:3.11\n",
            "第31周期，第500/938撮, 分类器Loss:0.10, 生成器Loss:5.72\n",
            "第31周期，第600/938撮, 分类器Loss:0.12, 生成器Loss:5.89\n",
            "第31周期，第700/938撮, 分类器Loss:0.17, 生成器Loss:8.12\n",
            "第31周期，第800/938撮, 分类器Loss:0.95, 生成器Loss:5.03\n",
            "第31周期，第900/938撮, 分类器Loss:0.08, 生成器Loss:3.83\n",
            "第32周期，第0/938撮, 分类器Loss:0.06, 生成器Loss:5.10\n",
            "第32周期，第100/938撮, 分类器Loss:0.13, 生成器Loss:7.29\n",
            "第32周期，第200/938撮, 分类器Loss:0.43, 生成器Loss:5.41\n",
            "第32周期，第300/938撮, 分类器Loss:1.18, 生成器Loss:3.21\n",
            "第32周期，第400/938撮, 分类器Loss:0.09, 生成器Loss:9.38\n",
            "第32周期，第500/938撮, 分类器Loss:0.25, 生成器Loss:6.38\n",
            "第32周期，第600/938撮, 分类器Loss:0.17, 生成器Loss:7.16\n",
            "第32周期，第700/938撮, 分类器Loss:0.24, 生成器Loss:7.41\n",
            "第32周期，第800/938撮, 分类器Loss:0.23, 生成器Loss:6.99\n",
            "第32周期，第900/938撮, 分类器Loss:0.12, 生成器Loss:5.24\n",
            "第33周期，第0/938撮, 分类器Loss:0.21, 生成器Loss:7.81\n",
            "第33周期，第100/938撮, 分类器Loss:0.08, 生成器Loss:3.19\n",
            "第33周期，第200/938撮, 分类器Loss:0.28, 生成器Loss:6.30\n",
            "第33周期，第300/938撮, 分类器Loss:0.29, 生成器Loss:3.98\n",
            "第33周期，第400/938撮, 分类器Loss:0.27, 生成器Loss:4.33\n",
            "第33周期，第500/938撮, 分类器Loss:0.17, 生成器Loss:7.21\n",
            "第33周期，第600/938撮, 分类器Loss:0.19, 生成器Loss:6.73\n",
            "第33周期，第700/938撮, 分类器Loss:0.30, 生成器Loss:3.59\n",
            "第33周期，第800/938撮, 分类器Loss:0.32, 生成器Loss:4.78\n",
            "第33周期，第900/938撮, 分类器Loss:0.24, 生成器Loss:6.00\n",
            "第34周期，第0/938撮, 分类器Loss:0.17, 生成器Loss:3.31\n",
            "第34周期，第100/938撮, 分类器Loss:0.06, 生成器Loss:7.86\n",
            "第34周期，第200/938撮, 分类器Loss:0.11, 生成器Loss:7.85\n",
            "第34周期，第300/938撮, 分类器Loss:0.11, 生成器Loss:3.19\n",
            "第34周期，第400/938撮, 分类器Loss:0.04, 生成器Loss:7.29\n",
            "第34周期，第500/938撮, 分类器Loss:0.18, 生成器Loss:6.94\n",
            "第34周期，第600/938撮, 分类器Loss:0.38, 生成器Loss:7.23\n",
            "第34周期，第700/938撮, 分类器Loss:0.19, 生成器Loss:8.20\n",
            "第34周期，第800/938撮, 分类器Loss:0.29, 生成器Loss:4.72\n",
            "第34周期，第900/938撮, 分类器Loss:0.16, 生成器Loss:7.33\n",
            "第35周期，第0/938撮, 分类器Loss:0.41, 生成器Loss:6.10\n",
            "第35周期，第100/938撮, 分类器Loss:0.14, 生成器Loss:8.05\n",
            "第35周期，第200/938撮, 分类器Loss:0.09, 生成器Loss:6.15\n",
            "第35周期，第300/938撮, 分类器Loss:0.10, 生成器Loss:3.03\n",
            "第35周期，第400/938撮, 分类器Loss:0.05, 生成器Loss:5.70\n",
            "第35周期，第500/938撮, 分类器Loss:0.38, 生成器Loss:7.84\n",
            "第35周期，第600/938撮, 分类器Loss:0.20, 生成器Loss:6.31\n",
            "第35周期，第700/938撮, 分类器Loss:0.22, 生成器Loss:4.00\n",
            "第35周期，第800/938撮, 分类器Loss:0.20, 生成器Loss:6.74\n",
            "第35周期，第900/938撮, 分类器Loss:0.36, 生成器Loss:5.74\n",
            "第36周期，第0/938撮, 分类器Loss:0.28, 生成器Loss:6.01\n",
            "第36周期，第100/938撮, 分类器Loss:0.36, 生成器Loss:3.17\n",
            "第36周期，第200/938撮, 分类器Loss:0.07, 生成器Loss:6.88\n",
            "第36周期，第300/938撮, 分类器Loss:0.10, 生成器Loss:9.21\n",
            "第36周期，第400/938撮, 分类器Loss:0.27, 生成器Loss:7.45\n",
            "第36周期，第500/938撮, 分类器Loss:0.15, 生成器Loss:6.55\n",
            "第36周期，第600/938撮, 分类器Loss:1.11, 生成器Loss:8.59\n",
            "第36周期，第700/938撮, 分类器Loss:0.37, 生成器Loss:4.95\n",
            "第36周期，第800/938撮, 分类器Loss:0.14, 生成器Loss:7.20\n",
            "第36周期，第900/938撮, 分类器Loss:0.05, 生成器Loss:7.71\n",
            "第37周期，第0/938撮, 分类器Loss:0.45, 生成器Loss:5.69\n",
            "第37周期，第100/938撮, 分类器Loss:0.37, 生成器Loss:5.53\n",
            "第37周期，第200/938撮, 分类器Loss:0.34, 生成器Loss:7.08\n",
            "第37周期，第300/938撮, 分类器Loss:0.16, 生成器Loss:3.54\n",
            "第37周期，第400/938撮, 分类器Loss:0.12, 生成器Loss:5.47\n",
            "第37周期，第500/938撮, 分类器Loss:0.06, 生成器Loss:5.35\n",
            "第37周期，第600/938撮, 分类器Loss:0.10, 生成器Loss:7.48\n",
            "第37周期，第700/938撮, 分类器Loss:0.22, 生成器Loss:5.87\n",
            "第37周期，第800/938撮, 分类器Loss:0.08, 生成器Loss:6.04\n",
            "第37周期，第900/938撮, 分类器Loss:0.17, 生成器Loss:8.23\n",
            "第38周期，第0/938撮, 分类器Loss:0.22, 生成器Loss:7.48\n",
            "第38周期，第100/938撮, 分类器Loss:0.14, 生成器Loss:3.22\n",
            "第38周期，第200/938撮, 分类器Loss:0.03, 生成器Loss:6.99\n",
            "第38周期，第300/938撮, 分类器Loss:0.19, 生成器Loss:10.47\n",
            "第38周期，第400/938撮, 分类器Loss:0.24, 生成器Loss:8.63\n",
            "第38周期，第500/938撮, 分类器Loss:0.29, 生成器Loss:7.28\n",
            "第38周期，第600/938撮, 分类器Loss:0.21, 生成器Loss:5.79\n",
            "第38周期，第700/938撮, 分类器Loss:0.45, 生成器Loss:7.12\n",
            "第38周期，第800/938撮, 分类器Loss:0.09, 生成器Loss:5.37\n",
            "第38周期，第900/938撮, 分类器Loss:0.07, 生成器Loss:8.11\n",
            "第39周期，第0/938撮, 分类器Loss:0.10, 生成器Loss:7.66\n",
            "第39周期，第100/938撮, 分类器Loss:0.21, 生成器Loss:4.99\n",
            "第39周期，第200/938撮, 分类器Loss:0.20, 生成器Loss:6.67\n",
            "第39周期，第300/938撮, 分类器Loss:0.12, 生成器Loss:5.88\n",
            "第39周期，第400/938撮, 分类器Loss:0.09, 生成器Loss:7.85\n",
            "第39周期，第500/938撮, 分类器Loss:0.07, 生成器Loss:6.26\n",
            "第39周期，第600/938撮, 分类器Loss:0.27, 生成器Loss:7.15\n",
            "第39周期，第700/938撮, 分类器Loss:0.21, 生成器Loss:7.93\n",
            "第39周期，第800/938撮, 分类器Loss:0.27, 生成器Loss:7.11\n",
            "第39周期，第900/938撮, 分类器Loss:0.38, 生成器Loss:7.76\n",
            "第40周期，第0/938撮, 分类器Loss:0.19, 生成器Loss:6.28\n",
            "第40周期，第100/938撮, 分类器Loss:0.13, 生成器Loss:6.22\n",
            "第40周期，第200/938撮, 分类器Loss:0.52, 生成器Loss:5.67\n",
            "第40周期，第300/938撮, 分类器Loss:0.08, 生成器Loss:5.09\n",
            "第40周期，第400/938撮, 分类器Loss:0.46, 生成器Loss:5.99\n",
            "第40周期，第500/938撮, 分类器Loss:0.15, 生成器Loss:4.04\n",
            "第40周期，第600/938撮, 分类器Loss:0.19, 生成器Loss:7.06\n",
            "第40周期，第700/938撮, 分类器Loss:0.13, 生成器Loss:6.49\n",
            "第40周期，第800/938撮, 分类器Loss:0.20, 生成器Loss:5.77\n",
            "第40周期，第900/938撮, 分类器Loss:0.21, 生成器Loss:5.47\n",
            "第41周期，第0/938撮, 分类器Loss:0.14, 生成器Loss:4.97\n",
            "第41周期，第100/938撮, 分类器Loss:1.49, 生成器Loss:8.66\n",
            "第41周期，第200/938撮, 分类器Loss:0.35, 生成器Loss:5.62\n",
            "第41周期，第300/938撮, 分类器Loss:0.32, 生成器Loss:6.77\n",
            "第41周期，第400/938撮, 分类器Loss:0.22, 生成器Loss:8.63\n",
            "第41周期，第500/938撮, 分类器Loss:0.06, 生成器Loss:5.94\n",
            "第41周期，第600/938撮, 分类器Loss:0.20, 生成器Loss:4.41\n",
            "第41周期，第700/938撮, 分类器Loss:0.48, 生成器Loss:5.37\n",
            "第41周期，第800/938撮, 分类器Loss:0.08, 生成器Loss:8.30\n",
            "第41周期，第900/938撮, 分类器Loss:0.19, 生成器Loss:8.66\n",
            "第42周期，第0/938撮, 分类器Loss:0.26, 生成器Loss:6.37\n",
            "第42周期，第100/938撮, 分类器Loss:0.49, 生成器Loss:7.35\n",
            "第42周期，第200/938撮, 分类器Loss:0.07, 生成器Loss:8.50\n",
            "第42周期，第300/938撮, 分类器Loss:0.19, 生成器Loss:3.11\n",
            "第42周期，第400/938撮, 分类器Loss:0.41, 生成器Loss:5.27\n",
            "第42周期，第500/938撮, 分类器Loss:0.15, 生成器Loss:6.62\n",
            "第42周期，第600/938撮, 分类器Loss:0.09, 生成器Loss:6.43\n",
            "第42周期，第700/938撮, 分类器Loss:0.06, 生成器Loss:4.82\n",
            "第42周期，第800/938撮, 分类器Loss:0.09, 生成器Loss:4.73\n",
            "第42周期，第900/938撮, 分类器Loss:0.35, 生成器Loss:5.14\n",
            "第43周期，第0/938撮, 分类器Loss:0.16, 生成器Loss:5.45\n",
            "第43周期，第100/938撮, 分类器Loss:0.57, 生成器Loss:1.08\n",
            "第43周期，第200/938撮, 分类器Loss:0.22, 生成器Loss:4.29\n",
            "第43周期，第300/938撮, 分类器Loss:0.34, 生成器Loss:6.65\n",
            "第43周期，第400/938撮, 分类器Loss:0.09, 生成器Loss:7.59\n",
            "第43周期，第500/938撮, 分类器Loss:0.21, 生成器Loss:5.54\n",
            "第43周期，第600/938撮, 分类器Loss:0.22, 生成器Loss:6.74\n",
            "第43周期，第700/938撮, 分类器Loss:0.14, 生成器Loss:2.89\n",
            "第43周期，第800/938撮, 分类器Loss:0.59, 生成器Loss:2.93\n",
            "第43周期，第900/938撮, 分类器Loss:0.34, 生成器Loss:8.38\n",
            "第44周期，第0/938撮, 分类器Loss:0.06, 生成器Loss:5.20\n",
            "第44周期，第100/938撮, 分类器Loss:0.30, 生成器Loss:3.43\n",
            "第44周期，第200/938撮, 分类器Loss:0.11, 生成器Loss:8.29\n",
            "第44周期，第300/938撮, 分类器Loss:0.05, 生成器Loss:8.21\n",
            "第44周期，第400/938撮, 分类器Loss:0.08, 生成器Loss:7.19\n",
            "第44周期，第500/938撮, 分类器Loss:0.05, 生成器Loss:8.89\n",
            "第44周期，第600/938撮, 分类器Loss:0.22, 生成器Loss:6.79\n",
            "第44周期，第700/938撮, 分类器Loss:0.33, 生成器Loss:8.78\n",
            "第44周期，第800/938撮, 分类器Loss:0.19, 生成器Loss:7.34\n",
            "第44周期，第900/938撮, 分类器Loss:0.11, 生成器Loss:7.05\n",
            "第45周期，第0/938撮, 分类器Loss:0.07, 生成器Loss:6.47\n",
            "第45周期，第100/938撮, 分类器Loss:0.45, 生成器Loss:2.98\n",
            "第45周期，第200/938撮, 分类器Loss:0.54, 生成器Loss:9.76\n",
            "第45周期，第300/938撮, 分类器Loss:0.07, 生成器Loss:5.09\n",
            "第45周期，第400/938撮, 分类器Loss:0.20, 生成器Loss:8.59\n",
            "第45周期，第500/938撮, 分类器Loss:0.29, 生成器Loss:6.86\n",
            "第45周期，第600/938撮, 分类器Loss:0.11, 生成器Loss:8.40\n",
            "第45周期，第700/938撮, 分类器Loss:0.24, 生成器Loss:4.12\n",
            "第45周期，第800/938撮, 分类器Loss:0.40, 生成器Loss:4.83\n",
            "第45周期，第900/938撮, 分类器Loss:0.33, 生成器Loss:4.10\n",
            "第46周期，第0/938撮, 分类器Loss:0.13, 生成器Loss:3.29\n",
            "第46周期，第100/938撮, 分类器Loss:0.16, 生成器Loss:5.41\n",
            "第46周期，第200/938撮, 分类器Loss:0.23, 生成器Loss:6.69\n",
            "第46周期，第300/938撮, 分类器Loss:0.17, 生成器Loss:6.21\n",
            "第46周期，第400/938撮, 分类器Loss:0.11, 生成器Loss:4.44\n",
            "第46周期，第500/938撮, 分类器Loss:0.44, 生成器Loss:6.62\n",
            "第46周期，第600/938撮, 分类器Loss:0.09, 生成器Loss:4.42\n",
            "第46周期，第700/938撮, 分类器Loss:0.05, 生成器Loss:7.18\n",
            "第46周期，第800/938撮, 分类器Loss:0.17, 生成器Loss:9.15\n",
            "第46周期，第900/938撮, 分类器Loss:1.14, 生成器Loss:3.12\n",
            "第47周期，第0/938撮, 分类器Loss:0.23, 生成器Loss:12.63\n",
            "第47周期，第100/938撮, 分类器Loss:0.19, 生成器Loss:7.77\n",
            "第47周期，第200/938撮, 分类器Loss:0.22, 生成器Loss:7.96\n",
            "第47周期，第300/938撮, 分类器Loss:0.33, 生成器Loss:6.03\n",
            "第47周期，第400/938撮, 分类器Loss:0.36, 生成器Loss:9.01\n",
            "第47周期，第500/938撮, 分类器Loss:1.27, 生成器Loss:10.58\n",
            "第47周期，第600/938撮, 分类器Loss:0.08, 生成器Loss:6.37\n",
            "第47周期，第700/938撮, 分类器Loss:0.13, 生成器Loss:5.56\n",
            "第47周期，第800/938撮, 分类器Loss:0.28, 生成器Loss:6.77\n",
            "第47周期，第900/938撮, 分类器Loss:0.16, 生成器Loss:4.71\n",
            "第48周期，第0/938撮, 分类器Loss:1.31, 生成器Loss:4.13\n",
            "第48周期，第100/938撮, 分类器Loss:0.26, 生成器Loss:6.96\n",
            "第48周期，第200/938撮, 分类器Loss:0.19, 生成器Loss:7.92\n",
            "第48周期，第300/938撮, 分类器Loss:0.06, 生成器Loss:7.40\n",
            "第48周期，第400/938撮, 分类器Loss:0.07, 生成器Loss:7.22\n",
            "第48周期，第500/938撮, 分类器Loss:0.33, 生成器Loss:7.00\n",
            "第48周期，第600/938撮, 分类器Loss:0.25, 生成器Loss:5.97\n",
            "第48周期，第700/938撮, 分类器Loss:0.08, 生成器Loss:6.18\n",
            "第48周期，第800/938撮, 分类器Loss:0.12, 生成器Loss:6.61\n",
            "第48周期，第900/938撮, 分类器Loss:0.26, 生成器Loss:9.77\n",
            "第49周期，第0/938撮, 分类器Loss:0.04, 生成器Loss:4.71\n",
            "第49周期，第100/938撮, 分类器Loss:0.01, 生成器Loss:7.26\n",
            "第49周期，第200/938撮, 分类器Loss:0.15, 生成器Loss:6.57\n",
            "第49周期，第300/938撮, 分类器Loss:0.08, 生成器Loss:5.66\n",
            "第49周期，第400/938撮, 分类器Loss:0.10, 生成器Loss:6.45\n",
            "第49周期，第500/938撮, 分类器Loss:0.29, 生成器Loss:7.85\n",
            "第49周期，第600/938撮, 分类器Loss:0.16, 生成器Loss:6.37\n",
            "第49周期，第700/938撮, 分类器Loss:0.26, 生成器Loss:5.68\n",
            "第49周期，第800/938撮, 分类器Loss:0.32, 生成器Loss:5.61\n",
            "第49周期，第900/938撮, 分类器Loss:0.34, 生成器Loss:5.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfbVb3eIaCPJ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tpCa20PaCv6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB6WLTv6aKg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HENelSg-akaK"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n3bk7eDaztx"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju1MBcO1a1IM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}